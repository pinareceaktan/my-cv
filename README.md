# Ece Aktan Hatipoglu
_AI Research Engineer, based in Trabzon, Turkey_ <br>

[Email](mailto:eceaktanhatipoglu@gmail.com) / [LinkedIn](https://www.linkedin.com/in/ecehtp/) / [GitHub](https://github.com/pinareceaktan) / 


## Experience üë©üèª‚Äçüíª
**Reseaerch Engineer** @ [Huawei]([website](https://www.huawei.com/tr/)) _(September 2019- Present)_<br>
- Implementing a _spelling correction_ model, for English, Spanish, Russian and Arabic for Huawei App Galery Search.
- Worked in semi-supervised learning and keyword extraction research projects. 
- Implemented a parallel corpus filtering pipeline in collaboration with AARC of
Huawei. Published a paper as a result and ranked in the EMNLP contest of WMT20.
- **_Technologies used:_** Python3.x, TensorFlow, PyTorch, NLTK, SpaCy, Scikit-learn, Pandas, Jupyter.
- **_Models used:_** Symspell, DeepPavlov, SimCLR, Moco, Contrastive Learning, Yake, Bert, m-Bart.
<br><br>

**Data Scientist** @ [Getir]([website](https://getir.com/)) _(May 2018- July 2019)_<br>
**Getir** is an online retails delivery app which provides <last than an hour> delivery. Their business model is similar to Glovo, only Getir has its own stores in each crucial spots in Istanbul where they keep/manage wide-definite products. The demand prediction and planning, couriers planning & assignments, marketing analysis are all carried by the Data team. 
- Sales Prediction: As a member of the Data department I was dedicated to solving Getir's biggest problem which is to predict daily orders & item- based sales. An accurate prediction of daily orders would help organization to employ the right amount of man power and help manage them the supply chain. I used Tensorflow's LSTM implementation for sales prediction and performed many feature engineering in that manner. Model achieves nearly 2% error rate.
- Employed regional hexagonal gridding system: To perform sales prediction I created a hexagonal gridding system which (as later I heard) is very popular among companies that depend on geographic analysis such as Uber. Hexagonal gridding helped the company to carry out location-based analyses such as classifying areas according to basket value, delivery cost, deciding the most efficient polygon borders for a store. Hexagons also create the baseline for sales prediction it prevents the ambiguity of region changes, killed the necessity of downloading and computing x years of data all over again because hexagons hold all the raw data and each hexagon is dynamically assigned to a store.  
- Campaign effect and precision clustering.  
- Geographic rival and risk factors analyses.  
- Implemented a sentiment analysis model to track public reliability of the company, by mining tweets that mentions the company using Twitter dev API.  
- Performed ad-hoc analyses to observe client RFM,campaign success and store region productivity.  
- **_Technologies used:_** Python 3.x, TensorFlow1.x, AWS, S3 buckets, MongoDB, RedShift, SQL, Jupyter Notebooks, Shapely, Tweepy, Scikit-Learn, Statsmodels.
- **_Models used:_** Bayes, ARIMA, SARIMA, LSTM, Clustering.
<br><br>

**AI Research Engineer** @ [Etiya](https://www.etiya.com/tr) _(Dec 2017- May 2018)_<br>
Explanation
- Developed a text-CNN model to identify street language and mocking in Turkish, model achieved a 88% percentage accuracy. Used Python and TensorFlow 1.x. 
- Lots of mining our own task-specific data using Python'a Scrapy and Tweepy.
- **_Technologies used:_** NLTK, SpaCy, Python3.x, TensorFlow1.x.
- **_Models used:_** TextCNN, Word2vec.
<br><br>

**Junior PHP Developer** @ [Ubit](https://www.ubit.com.tr/) _(Jul 2014- Sept 2015)_<br>
Worked as a backend PHP developer, for their school management platform called [STOYS](https://stoys.co/)
- Designed the back-end of the web pages for STOYS.
- Assisted in re-designing the DB during version upgrade of the STOYS.
- **_Technologies used:_** PHP, Zen Framework, SQL.
<br><br>

## Education üìöüñå
**Computer Engineering** <br>
[Bahcesehir University](https://bau.edu.tr/) - Istanbul, Turkey _(2018-Droped out at thesis)_
- **_Major courses completed:_** Data mining, Computer vision, Machine learning. 

**BS in Software Engineering** <br>
[Bahcesehir University](https://bau.edu.tr/) - Istanbul, Turkey _(2010-2015)_
<br>

## Site Projects üêù
- 2022 Finding the trace of adverse childhood experiences in reddit micro blogs.
- 2020 Accident prediction on notifications posted by local municipality on Twitter. 
- 2018 Advertising placement for the Twitch game streams.


## PUBLICATIONS üî¶
  
- [1] H.Acarcicek,T.√áolakoglu,P.E.A.Hatipoglu,C.H.Huang,andW.Peng.Filtering noisy parallel corpus using transformers with proxy task learning. In Proceedings of the Fifth Conference on Machine Translation, pages 940‚Äì946, 2020.
- [2] P.E.Aktan,G.Hatipoglu,andN.Arica.Risk classification for breast cancer diagnosis using her2 testing. In 2016 24th Signal Processing and Communication Application Conference (SIU), pages 2133‚Äì2136. IEEE, 2016.
